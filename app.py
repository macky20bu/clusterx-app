# ClusterX Insight Engine v7.5 (Streamlit Cloud Deployed Ver)
# Base: Ver4.0
# Integrated Features: Ver5.0 (Investment Mode, Enjoyment Mode)
# New Feature: Dynamic Analyzer Panel (v6.0 Enjoyment Mode)
# Major Update: RPT1-13 Evaluation Logic (Ver.13.0 Final)
# Refactoring: v7.5 (Final UI Adjustments for Dynamic Analyzer)
# Note: Investment history feature removed for cloud deployment.

import streamlit as st
import pandas as pd
import numpy as np
import os
from datetime import datetime
from math import comb
from pathlib import Path
from itertools import product, combinations
import re

# ===================================================================
# 1. å®šæ•°ãƒ»è¨­å®šã‚¨ãƒªã‚¢
# ===================================================================

# --- ãƒ‘ã‚¹è¨­å®š ---
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆ(.py)ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™
APP_DIR = Path(__file__).parent
PERFORMANCE_DB_PATH = APP_DIR / "analyzer_performance_db_v1.1_20250720.csv"


# --- RPTè©•ä¾¡ãƒ«ãƒ¼ãƒ«è¨­å®š (Ver.13.0 Final) ---
RPT_RULES_CONFIG = {
    1: {
        'C_EXPECTANCY': 0.85, 'C_FUKUSHO_RATE': 0.10, 'D_EXPECTANCY': 0.60,
        'B_EXPECTANCY_RANGE': (0.65, 0.80),
    },
    2: {
        'D_TANSHO_EXPECTANCY_RANGE': (0.5, 0.7), 'D_BB_INDEX_THRESHOLD': 55.0,
        'D_C_NINKI_VALUES': {2, 3, 4}, 'E_EXPECTANCY': 1.15, 'AA_EXPECTANCY': 0.80,
    },
    3: {
        'B_EXPECTANCY_RANGE': (0.50, 0.60), 'C_EXPECTANCY': 0.85,
        'D_EXPECTANCY_RANGE': (0.90, 1.10), 'S_EXPECTANCY': 1.10, 'AA_EXPECTANCY': 0.90,
    },
    4: {
        'C_EXPECTANCY_RANGE': (0.80, 0.90), 'E_EXPECTANCY_RANGE': (0.90, 1.00),
        'SA_EXPECTANCY': 0.90, 'B_EXPECTANCY_RANGE': (0.70, 0.80),
    },
    5: {
        'C_EXPECTANCY': 0.90, 'D_EXPECTANCY_RANGE': (0.80, 0.85),
        'B_EXPECTANCY': 0.50, 'A_EXPECTANCY': 0.85, 'B_EXPECTANCY_RANGE': (0.70, 0.85),
    },
    6: {
        'A_TANSHO_EXPECTANCY': 0.80, 'A_FUKUSHO_EXPECTANCY': 0.65, 'SSS_EXPECTANCY': 0.85,
    },
    7: {
        'AA_A_EXPECTANCY': 0.80,
    },
    8: {
        'C_EXPECTANCY_RANGE': (0.55, 0.80), 'S_EXPECTANCY': 0.75,
    },
    9: {
        'C_EXPECTANCY_RANGE': (0.50, 0.85), 'E_EXPECTANCY': 0.85, 'S_EXPECTANCY': 0.75,
    },
    10: {
        'B_EXPECTANCY': 0.80,
    },
    11: {
        'A_EXPECTANCY': 0.65, 'S_EXPECTANCY': 0.75,
    },
    12: {
        'A_EXPECTANCY': 0.70, 'S_EXPECTANCY': 0.70,
    },
    13: {
        'A_EXPECTANCY': 0.65,
    }
}

# ===================================================================
# 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–¢æ•°ç¾¤
# ===================================================================

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ---

@st.cache_data
def load_performance_db():
    """éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(PERFORMANCE_DB_PATH):
        st.error(f"ã‚¨ãƒ©ãƒ¼: {PERFORMANCE_DB_PATH.name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚app.pyã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return pd.DataFrame()
    try:
        return pd.read_csv(PERFORMANCE_DB_PATH, header=0, encoding='utf_8_sig', on_bad_lines='skip')
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹DBã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

# --- ãƒ‡ãƒ¼ã‚¿è§£æãƒ»è©•ä¾¡é–¢æ•° ---

def parse_markdown_race_table(markdown_text: str):
    """Markdownå½¢å¼ã®å‡ºé¦¬è¡¨ã‚’è§£æã—ã€DataFrameã¨ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è¿”ã™"""
    lines = markdown_text.strip().splitlines()
    race_info_line = next((line for line in lines if "ãƒ¬ãƒ¼ã‚¹æƒ…å ±" in line), "")
    race_info = race_info_line.replace("ğŸ‡", "").replace("ãƒ¬ãƒ¼ã‚¹æƒ…å ±ï¼š", "").strip()
    table_lines = [line for line in lines if line.strip().startswith("|")]
    if len(table_lines) < 3: raise ValueError("Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã¨åŒºåˆ‡ã‚Šç·šã€ãƒ‡ãƒ¼ã‚¿è¡ŒãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    header_line, data_lines = table_lines[0], table_lines[2:]
    headers = [h.strip() for h in header_line.split("|")[1:-1]]
    rows = []
    for line in data_lines:
        cells = [c.strip() for c in line.split("|")[1:-1]]
        if len(cells) == len(headers):
            rows.append(dict(zip(headers, cells)))

    df = pd.DataFrame(rows)

    if 'é¦¬ç•ª' in df.columns:
        df['é¦¬ç•ª'] = pd.to_numeric(df['é¦¬ç•ª'], errors='coerce')
        df.dropna(subset=['é¦¬ç•ª'], inplace=True)
        df['é¦¬ç•ª'] = df['é¦¬ç•ª'].astype(int)

    if 'BBé †ä½' in df.columns:
        df['BBé †ä½'] = df['BBé †ä½'].str.replace('BB', '', regex=False)
    
    if 'ãƒ©ãƒ³ã‚¯' not in df.columns:
        st.warning("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«'ãƒ©ãƒ³ã‚¯'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è©•ä¾¡ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        df['ãƒ©ãƒ³ã‚¯'] = 'C'

    for col in ['å‹ç‡', 'é€£å¯¾ç‡', 'è¤‡å‹ç‡']:
        if col in df.columns: df[col] = pd.to_numeric(df[col].str.replace('%', '', regex=False), errors='coerce') / 100.0
    
    for col in ['Cäººæ°—', 'BBæŒ‡æ•°', 'å˜å‹ã‚ªãƒƒã‚º', 'è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™']:
        if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')

    if 'ãƒ¡ãƒ³ãƒãƒ¼æ¨å¥¨' not in df.columns:
        df['ãƒ¡ãƒ³ãƒãƒ¼æ¨å¥¨'] = ''
        
    return df, race_info

# --- RPTåˆ¥è©•ä¾¡é–¢æ•°ç¾¤ ---
def evaluate_rpt1_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[1]
    cond_maru = ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['C_EXPECTANCY']) & (df_eval['è¤‡å‹ç‡'] >= config['C_FUKUSHO_RATE'])) | \
                ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'D') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] < config['D_EXPECTANCY']))
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['B_EXPECTANCY_RANGE'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru, cond_sankaku], ['â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt2_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[2]
    df_eval['è©•ä¾¡'] = ''
    is_excluded = (df_eval['RPT'] == 2) & (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'AA')
    eligible_horses = df_eval[~is_excluded].copy()
    if not eligible_horses.empty:
        cond_tankatsu = ((eligible_horses['ç·åˆãƒ©ãƒ³ã‚¯'] == 'D') & eligible_horses['Web_å˜å‹æœŸå¾…å€¤'].between(*config['D_TANSHO_EXPECTANCY_RANGE']) & ((eligible_horses['BBæŒ‡æ•°'] < config['D_BB_INDEX_THRESHOLD']) | eligible_horses['Cäººæ°—'].isin(config['D_C_NINKI_VALUES'])))
        cond_maru = (eligible_horses['ç·åˆãƒ©ãƒ³ã‚¯'] == 'E') & (eligible_horses['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['E_EXPECTANCY'])
        cond_sankaku = ((eligible_horses['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') | ((eligible_horses['ç·åˆãƒ©ãƒ³ã‚¯'] == 'AA') & (eligible_horses['Web_è¤‡å‹æœŸå¾…å€¤'] < config['AA_EXPECTANCY'])))
        eligible_horses['è©•ä¾¡'] = np.select([cond_tankatsu, cond_maru, cond_sankaku], ['â—‰', 'â—', 'â–²'], default='')
        df_eval.update(eligible_horses)
    return df_eval

def evaluate_rpt3_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[3]
    cond_maru = ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['B_EXPECTANCY_RANGE'])) | \
                ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['C_EXPECTANCY'])) | \
                ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'D') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['D_EXPECTANCY_RANGE']))
    cond_sankaku = ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['S_EXPECTANCY'])) | \
                   ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'AA') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['AA_EXPECTANCY']))
    df_eval['è©•ä¾¡'] = np.select([cond_maru, cond_sankaku], ['â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt4_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[4]
    cond_maru_tankatsu_c = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['C_EXPECTANCY_RANGE'])
    cond_maru_e = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'E') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['E_EXPECTANCY_RANGE'])
    cond_maru_sa = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'].isin(['S', 'A'])) & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['SA_EXPECTANCY'])
    cond_tankatsu_b = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['B_EXPECTANCY_RANGE'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru_tankatsu_c, cond_maru_e, cond_maru_sa, cond_tankatsu_b], ['â— â—‰', 'â—', 'â—', 'â—‰'], default='')
    return df_eval

def evaluate_rpt5_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[5]
    cond_maru_tankatsu_c = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['C_EXPECTANCY'])
    cond_maru_tankatsu_d = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'D') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['D_EXPECTANCY_RANGE'])
    cond_maru_b = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] < config['B_EXPECTANCY'])
    cond_sankaku = ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['A_EXPECTANCY'])) | \
                   ((df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['B_EXPECTANCY_RANGE']))
    df_eval['è©•ä¾¡'] = np.select([cond_maru_tankatsu_c, cond_maru_tankatsu_d, cond_maru_b, cond_sankaku], ['â— â—‰', 'â— â—‰', 'â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt6_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[6]
    cond_tankatsu_a = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_å˜å‹æœŸå¾…å€¤'] >= config['A_TANSHO_EXPECTANCY'])
    cond_maru_a = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] < config['A_FUKUSHO_EXPECTANCY'])
    cond_sankaku_sss = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'SSS') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['SSS_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_tankatsu_a, cond_maru_a, cond_sankaku_sss], ['â—‰', 'â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt7_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[7]
    cond_maru_sss = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'SSS')
    cond_sankaku_aa_a = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'].isin(['A', 'AA'])) & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['AA_A_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru_sss, cond_sankaku_aa_a], ['â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt8_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[8]
    cond_maru_tankatsu = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['C_EXPECTANCY_RANGE'])
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['S_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru_tankatsu, cond_sankaku], ['â— â—‰', 'â–²'], default='')
    return df_eval

def evaluate_rpt9_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[9]
    cond_maru_tankatsu = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'C') & df_eval['Web_è¤‡å‹æœŸå¾…å€¤'].between(*config['C_EXPECTANCY_RANGE'])
    cond_maru = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'E') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['E_EXPECTANCY'])
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['S_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru_tankatsu, cond_maru, cond_sankaku], ['â— â—‰', 'â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt10_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[10]
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'B') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['B_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_sankaku], ['â–²'], default='')
    return df_eval

def evaluate_rpt11_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[11]
    cond_maru = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['A_EXPECTANCY'])
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['S_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru, cond_sankaku], ['â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt12_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[12]
    cond_maru = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['A_EXPECTANCY'])
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['S_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_maru, cond_sankaku], ['â—', 'â–²'], default='')
    return df_eval

def evaluate_rpt13_rules(df_eval: pd.DataFrame) -> pd.DataFrame:
    config = RPT_RULES_CONFIG[13]
    cond_sankaku = (df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] == 'A') & (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= config['A_EXPECTANCY'])
    df_eval['è©•ä¾¡'] = np.select([cond_sankaku], ['â–²'], default='')
    return df_eval

# --- å¸ä»¤å¡”ï¼ˆãƒ«ãƒ¼ã‚¿ãƒ¼ï¼‰é–¢æ•° ---
def evaluate_data(df, rpt_number):
    """
    ã€v7.5ã€‘RPTç•ªå·ã«åŸºã¥ãã€é©åˆ‡ãªè©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã™å¸ä»¤å¡”ï¼ˆãƒ«ãƒ¼ã‚¿ãƒ¼ï¼‰ã€‚
    """
    df_eval = df.copy()
    df_eval['RPT'] = rpt_number

    # --- 1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† ---
    if 'ãƒ©ãƒ³ã‚¯' not in df_eval.columns:
        st.warning("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«'ãƒ©ãƒ³ã‚¯'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è©•ä¾¡ã«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤'C'ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] = 'C'
    else:
        df_eval['ç·åˆãƒ©ãƒ³ã‚¯'] = df_eval['ãƒ©ãƒ³ã‚¯'].astype(str)

    df_eval['pattern'] = list(zip(df_eval['RPT'], df_eval['ç·åˆãƒ©ãƒ³ã‚¯']))

    numeric_cols_for_eval = ['è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™', 'é€£å¯¾ç‡', 'è¤‡å‹ç‡', 'å˜å‹ã‚ªãƒƒã‚º', 'å‹ç‡', 'BBæŒ‡æ•°', 'Cäººæ°—']
    for col in numeric_cols_for_eval:
        if col in df_eval.columns:
            df_eval[col] = pd.to_numeric(df_eval[col], errors='coerce').fillna(0)
        else:
            df_eval[col] = 0
            st.warning(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«ã€Œ{col}ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨ˆç®—ã«ã¯0ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    # --- 2. æœŸå¾…å€¤è¨ˆç®— ---
    num_runners = len(df_eval)
    correct_hit_rate = df_eval['é€£å¯¾ç‡'] if num_runners <= 7 else df_eval['è¤‡å‹ç‡']
    df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] = df_eval['è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™'] * correct_hit_rate
    df_eval['Web_å˜å‹æœŸå¾…å€¤'] = df_eval['å˜å‹ã‚ªãƒƒã‚º'] * df_eval['å‹ç‡']

    # --- 3. è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ ---
    df_eval['è©•ä¾¡'] = ''

    PROMISING_COMBINATIONS_V21 = set([
        (13, 'SSS'), (10, 'SSS'), (8, 'S'), (4, 'A'), (2, 'S'), (4, 'SSS'), (12, 'SS'), (7, 'A'), 
        (11, 'SSS'), (5, 'S'), (9, 'AA'), (3, 'S'), (7, 'SSS'), (11, 'SS'), (13, 'SS'), (5, 'A'), 
        (6, 'SSS'), (8, 'A'), (9, 'S'), (5, 'SS'), (1, 'C'), (13, 'AA'), (3, 'C'), (13, 'A'), 
        (10, 'SS'), (13, 'B'), (7, 'SS'), (7, 'AA'), (12, 'A')
    ])
    is_honmei_A_cond = (df_eval['pattern'].isin(PROMISING_COMBINATIONS_V21)) & \
                       (df_eval['Web_è¤‡å‹æœŸå¾…å€¤'] >= 0.85) & \
                       (df_eval['è¤‡å‹ç‡'] > 0.10)
    df_eval.loc[is_honmei_A_cond, 'è©•ä¾¡'] = 'â—+'

    rpt_function_map = {
        1: evaluate_rpt1_rules, 2: evaluate_rpt2_rules, 3: evaluate_rpt3_rules,
        4: evaluate_rpt4_rules, 5: evaluate_rpt5_rules, 6: evaluate_rpt6_rules,
        7: evaluate_rpt7_rules, 8: evaluate_rpt8_rules, 9: evaluate_rpt9_rules,
        10: evaluate_rpt10_rules, 11: evaluate_rpt11_rules, 12: evaluate_rpt12_rules,
        13: evaluate_rpt13_rules,
    }
    
    non_plus_horses_mask = df_eval['è©•ä¾¡'] != 'â—+'
    if non_plus_horses_mask.any():
        non_plus_horses = df_eval[non_plus_horses_mask].copy()
        evaluation_function = rpt_function_map.get(rpt_number)
        if evaluation_function:
            evaluated_non_plus = evaluation_function(non_plus_horses)
            df_eval.update(evaluated_non_plus)

    # --- 4. è£œè¶³ãƒ•ãƒ©ã‚°ã®è¨ˆç®— ---
    df_eval['is_honmei'] = df_eval['è©•ä¾¡'].apply(lambda x: 'â—' in x or 'â—‰' in x)
    df_eval['â—'] = df_eval['è©•ä¾¡'].apply(lambda x: 'â—' if 'â—' in x else '')
    
    def assign_star_rank(row):
        if not row['is_honmei']: return ''
        cond_A = row['å‹ç‡'] >= 0.40
        cond_B = (row['ç·åˆãƒ©ãƒ³ã‚¯'] == 'S') and (row['RPT'] in [8, 9])
        cond_C = (row['ç·åˆãƒ©ãƒ³ã‚¯'] == 'SSS') and (row['BBæŒ‡æ•°'] >= 70)
        cond_D = (row['RPT'] in [3, 6, 8, 11]) and (row['å˜å‹ã‚ªãƒƒã‚º'] < 2.0)
        if cond_A or cond_B or cond_C or cond_D: return 'â˜†+'
        if row['é€£å¯¾ç‡'] >= 0.50: return 'â˜†'
        return 'â˜†-'
    df_eval['â˜†è©•ä¾¡'] = df_eval.apply(assign_star_rank, axis=1)

    df_eval['RPTè©•ä¾¡'] = ''
    return df_eval

# --- ãã®ä»–ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–¢æ•° ---

def generate_investment_recommendations(evaluated_race_df: pd.DataFrame):
    """æŠ•è³‡å¯¾è±¡é¦¬åˆ¸ï¼ˆâ—+, â—, â—‰ï¼‰ã‚’æŠ½å‡ºãƒ»ç”Ÿæˆã™ã‚‹"""
    investment_targets_df = evaluated_race_df[evaluated_race_df['is_honmei']].copy()
    if investment_targets_df.empty:
        return pd.DataFrame()
    
    def assign_units(evaluation):
        if 'â—+' in evaluation: return 3.0
        if 'â—' in evaluation: return 2.0
        if 'â—‰' in evaluation: return 2.0
        return 0.0

    investment_targets_df['æŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ'] = investment_targets_df['è©•ä¾¡'].apply(assign_units)
    
    output_columns = ['é¦¬ç•ª', 'é¦¬å', 'è©•ä¾¡', 'æŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ', 'è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™']
    final_columns = [col for col in output_columns if col in investment_targets_df.columns]
    
    return investment_targets_df[final_columns].reset_index(drop=True)

def get_dynamic_analysis_data(perf_db: pd.DataFrame, rpt: int, rank: str, exp_val: float):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹DBã‹ã‚‰é¡ä¼¼æ¡ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ç”¨ï¼‰"""
    results = {'pinpoint': None, 'downward': None, 'upward': None}
    if perf_db.empty: return results

    subset_df = perf_db[(perf_db['RPT'] == rpt) & (perf_db['ç·åˆãƒ©ãƒ³ã‚¯'] == rank)].copy()
    if subset_df.empty: return results

    def parse_range_midpoint(range_str):
        if pd.isna(range_str): return np.nan
        try:
            clean_str = str(range_str).replace('[', '').replace(')', '')
            lower, upper = map(float, clean_str.split(', '))
            return (lower + upper) / 2
        except: return np.nan
    
    subset_df['mid_range_exp_val'] = subset_df['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸'].apply(parse_range_midpoint)
    subset_df.dropna(subset=['mid_range_exp_val'], inplace=True)
    if subset_df.empty: return results

    diff = (subset_df['mid_range_exp_val'] - exp_val).abs()
    if diff.empty: return results
    
    closest_index = diff.idxmin()
    pinpoint_data = subset_df.loc[closest_index]
    results['pinpoint'] = pinpoint_data.to_dict()

    sorted_subset = subset_df.sort_values('mid_range_exp_val').reset_index(drop=True)
    pinpoint_loc_series = sorted_subset[sorted_subset['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸'] == pinpoint_data['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸']].index
    if not pinpoint_loc_series.empty:
        pinpoint_loc = pinpoint_loc_series[0]
        if pinpoint_loc > 0:
            results['downward'] = sorted_subset.iloc[pinpoint_loc - 1].to_dict()
        if pinpoint_loc < len(sorted_subset) - 1:
            results['upward'] = sorted_subset.iloc[pinpoint_loc + 1].to_dict()
            
    return results

def calculate_combinations(bet_type, jiku_list, aite_list):
    """é¦¬åˆ¸ã®çµ„ã¿åˆã‚ã›ç‚¹æ•°ã‚’è¨ˆç®—ã™ã‚‹"""
    jiku_count, aite_count = len(jiku_list), len(aite_list)
    if jiku_count == 0: return 0
    if bet_type == "3é€£è¤‡":
        if jiku_count == 1: return comb(aite_count, 2) if aite_count >= 2 else 0
        if jiku_count == 2: return aite_count
        return comb(jiku_count, 3)
    elif bet_type == "3é€£å˜":
        if jiku_count == 1: return aite_count * (aite_count - 1) if aite_count >= 2 else 0
        if jiku_count == 2: return 2 * aite_count
    return 0

# ===================================================================
# 3. UIæç”»é–¢æ•°ç¾¤
# ===================================================================

def render_investment_ui(investment_recs, race_info):
    """ã€ŒæŠ•è³‡ç«¶é¦¬ã€ã‚¿ãƒ–ã®UIã‚’æç”»ã™ã‚‹ (å±¥æ­´æ©Ÿèƒ½ãªã—)"""
    st.subheader(f"æŠ•è³‡ç«¶é¦¬ãƒ¢ãƒ¼ãƒ‰: {race_info}")
    
    if not investment_recs.empty:
        display_recs = investment_recs.copy()
        unit_value = st.session_state.current_unit_value
        display_recs['æŠ•è³‡é‡‘é¡ (å††)'] = (display_recs['æŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ'] * unit_value).astype(int)

        st.subheader("æœ¬ãƒ¬ãƒ¼ã‚¹ã®æŠ•è³‡æ¨å¥¨é¦¬åˆ¸")
        st.dataframe(display_recs[['é¦¬ç•ª', 'é¦¬å', 'è©•ä¾¡', 'æŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ', 'æŠ•è³‡é‡‘é¡ (å††)']], hide_index=True, use_container_width=True)

        total_units = display_recs['æŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ'].sum()
        total_investment_yen = display_recs['æŠ•è³‡é‡‘é¡ (å††)'].sum()
        
        st.metric(label="åˆè¨ˆæŠ•è³‡ãƒ¦ãƒ‹ãƒƒãƒˆ", value=f"{total_units:.1f} U")
        st.metric(label="åˆè¨ˆæŠ•è³‡é‡‘é¡", value=f"{total_investment_yen:,} å††")
    else:
        st.info("ã“ã®ãƒ¬ãƒ¼ã‚¹ã«ã¯æŠ•è³‡æ¨å¥¨é¦¬åˆ¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def _render_detailed_stats(data, bet_type_jp):
    """ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®è©³ç´°ãªæˆç¸¾ãƒ–ãƒ­ãƒƒã‚¯ã‚’æç”»ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    st.metric(label=f"{bet_type_jp}å›åç‡", value=f"{data.get(f'{bet_type_jp}å›åç‡(%)', 0):.0f}%")
    st.metric(label=f"{bet_type_jp}çš„ä¸­ç‡", value=f"{data.get(f'{bet_type_jp}çš„ä¸­ç‡(%)', 0):.1f}%")
    st.markdown(f"""
    - **è©¦è¡Œå›æ•°:** {data.get('è©¦è¡Œå›æ•°', 0)} å›
    - **çš„ä¸­æ•°:** {data.get(f'{bet_type_jp}çš„ä¸­æ•°', 0)} å›
    - **æŠ•è³‡é¡:** {int(data.get(f'{bet_type_jp}æŠ•è³‡é¡', 0)):,} å††
    - **æ‰•æˆ»é¡:** {int(data.get(f'{bet_type_jp}æ‰•æˆ»é¡', 0)):,} å††
    """)

def render_dynamic_analyzer_panel(horse_data, perf_db):
    """ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ãƒ»ãƒ‘ãƒãƒ«ã‚’æç”»ã™ã‚‹ (UIæ”¹å–„ç‰ˆ)"""
    st.header(f"ğŸ´ {horse_data['é¦¬ç•ª']}. {horse_data['é¦¬å']} ã®æœŸå¾…å€¤åˆ†æ")
    
    analysis_data = get_dynamic_analysis_data(perf_db, rpt=horse_data['RPT'], rank=horse_data['ç·åˆãƒ©ãƒ³ã‚¯'], exp_val=horse_data['Web_è¤‡å‹æœŸå¾…å€¤'])

    if analysis_data['pinpoint']:
        data = analysis_data['pinpoint']
        st.subheader("ğŸ“Š é¡ä¼¼æ¡ä»¶ã®éå»æˆç¸¾")
        st.info(f"ç¾åœ¨ã®æœŸå¾…å€¤ `{horse_data['Web_è¤‡å‹æœŸå¾…å€¤']:.2f}` ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ (æœŸå¾…å€¤ãƒ¬ãƒ³ã‚¸: **{data['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸']}**)")

        with st.container(border=True):
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("è¤‡å‹ (Place) æˆç¸¾")
                _render_detailed_stats(data, "è¤‡å‹")
            with col2:
                st.subheader("å˜å‹ (Win) æˆç¸¾")
                _render_detailed_stats(data, "å˜å‹")
        
        st.markdown("---")
        col3, col4 = st.columns(2)
        with col3:
            with st.container(border=True):
                st.subheader("â–¼ ä¸‹ä½äº’æ›ã®è¤‡å‹æˆç¸¾")
                if analysis_data['downward']:
                    down_data = analysis_data['downward']
                    st.info(f"æœŸå¾…å€¤ãƒ¬ãƒ³ã‚¸: **{down_data['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸']}**")
                    _render_detailed_stats(down_data, "è¤‡å‹")
                else:
                    st.write("ãƒ‡ãƒ¼ã‚¿ãªã—")
        with col4:
            with st.container(border=True):
                st.subheader("â–² ä¸Šä½äº’æ›ã®è¤‡å‹æˆç¸¾")
                if analysis_data['upward']:
                    up_data = analysis_data['upward']
                    st.info(f"æœŸå¾…å€¤ãƒ¬ãƒ³ã‚¸: **{up_data['Web_è¤‡å‹æœŸå¾…å€¤_ãƒ¬ãƒ³ã‚¸']}**")
                    _render_detailed_stats(up_data, "è¤‡å‹")
                else:
                    st.write("ãƒ‡ãƒ¼ã‚¿ãªã—")
    else:
        st.warning("é¡ä¼¼æ¡ä»¶ã®éå»ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def render_enjoyment_ui(race_data, perf_db, race_info):
    """ã€Œã‚¨ãƒ³ã‚¸ãƒ§ã‚¤ç«¶é¦¬ã€ã‚¿ãƒ–ã®UIã‚’æç”»ã™ã‚‹"""
    st.subheader(f"ğŸ‡ é¦¬åˆ¸æ¤œè¨ãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ³ãƒ: {race_info}")
    
    st.subheader("è©•ä¾¡çµæœä¸€è¦§")
    display_cols = ['é¦¬ç•ª', 'é¦¬å', 'Cäººæ°—', 'è©•ä¾¡', 'â˜†è©•ä¾¡', 'ãƒ¡ãƒ³ãƒãƒ¼æ¨å¥¨', 'å‹ç‡', 'é€£å¯¾ç‡', 'è¤‡å‹ç‡', 'Web_å˜å‹æœŸå¾…å€¤', 'Web_è¤‡å‹æœŸå¾…å€¤', 'å˜å‹ã‚ªãƒƒã‚º', 'è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™', 'BBæŒ‡æ•°', 'ç·åˆãƒ©ãƒ³ã‚¯']
    display_cols_exist = [col for col in display_cols if col in race_data.columns]
    st.dataframe(race_data[display_cols_exist].set_index('é¦¬ç•ª'), use_container_width=True)
    st.caption("è©•ä¾¡: â—+/â—/â—‰/â–² | â˜†è©•ä¾¡: â˜†+/â˜†/â˜†- | ãƒ¡ãƒ³ãƒãƒ¼æ¨å¥¨: æ‰‹å‹•æ¨å¥¨")
    
    st.markdown("---")
    st.subheader("ğŸ”¬ ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼")
    horse_options = ['é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„...'] + [f"{row['é¦¬ç•ª']}. {row['é¦¬å']}" for index, row in race_data.iterrows()]
    selected_horse_str = st.selectbox("åˆ†æã—ãŸã„é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„", options=horse_options, key="analyzer_horse_select")

    if selected_horse_str and selected_horse_str != 'é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„...':
        selected_horse_num = int(selected_horse_str.split('.')[0])
        filtered_df = race_data[race_data['é¦¬ç•ª'] == selected_horse_num]
        if not filtered_df.empty:
            selected_horse_data = filtered_df.iloc[0]
            render_dynamic_analyzer_panel(selected_horse_data, perf_db)
        
            st.markdown("---")
            st.subheader("ä»®æƒ³é¦¬åˆ¸ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
            bet_type = st.selectbox("åˆ¸ç¨®", ["3é€£è¤‡", "3é€£å˜"], key="sim_bet_type")
            col_jiku, col_aite = st.columns(2)
            with col_jiku:
                jiku_horses = st.multiselect("è»¸é¦¬", options=race_data['é¦¬ç•ª'].tolist(), format_func=lambda x: f"{x}ç•ª {race_data.loc[race_data['é¦¬ç•ª'] == x, 'é¦¬å'].iloc[0]}", key="jiku_horses_select")
            with col_aite:
                aite_horses = st.multiselect("ç›¸æ‰‹é¦¬", options=[h for h in race_data['é¦¬ç•ª'].tolist() if h not in jiku_horses], format_func=lambda x: f"{x}ç•ª {race_data.loc[race_data['é¦¬ç•ª'] == x, 'é¦¬å'].iloc[0]}", key="aite_horses_select")
            
            num_combinations = calculate_combinations(bet_type, jiku_horses, aite_horses)
            st.info(f"çµ„ã¿åˆã‚ã›æ•°: **{num_combinations}ç‚¹**")
        else:
             st.error("é¸æŠã•ã‚ŒãŸé¦¬ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ===================================================================
# 4. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œéƒ¨
# ===================================================================
def main():
    st.set_page_config(page_title="ClusterX Insight Engine", layout="wide")
    st.title("ClusterX Insight Engine")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
    if 'evaluated_data' not in st.session_state: st.session_state.evaluated_data = pd.DataFrame()
    if 'race_info' not in st.session_state: st.session_state.race_info = ""
    if 'markdown_input_prev' not in st.session_state: st.session_state.markdown_input_prev = ''
    if 'rpt_number_prev' not in st.session_state: st.session_state.rpt_number_prev = 1
    if 'current_budget' not in st.session_state: st.session_state.current_budget = 100000
    if 'current_unit_value' not in st.session_state: st.session_state.current_unit_value = 100

    # --- ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ ---
    performance_db = load_performance_db()

    # --- UIã‚¿ãƒ– ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›", "ğŸ“ˆ æŠ•è³‡ç«¶é¦¬", "ğŸ‡ ã‚¨ãƒ³ã‚¸ãƒ§ã‚¤ç«¶é¦¬"])

    with tab1:
        st.subheader("ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å…¥åŠ› & è©•ä¾¡å®Ÿè¡Œ")
        with st.form("data_input_form"):
            markdown_input = st.text_area("å‡ºé¦¬è¡¨ï¼ˆMarkdownå½¢å¼ï¼‰", height=250, value=st.session_state.markdown_input_prev)
            rpt_number = st.number_input("RPTç•ªå·", min_value=1, max_value=13, value=st.session_state.rpt_number_prev, step=1)
            
            st.markdown("---")
            st.subheader("è³‡é‡‘è¨­å®š")
            col_budget, col_unit = st.columns(2)
            with col_budget:
                st.session_state.current_budget = st.number_input("æœ¬æ—¥ã®ç·äºˆç®—(å††)", min_value=1000, step=1000, value=st.session_state.current_budget)
            with col_unit:
                st.session_state.current_unit_value = st.number_input("1ãƒ¦ãƒ‹ãƒƒãƒˆã‚ãŸã‚Šã®é‡‘é¡(å††)", min_value=100, step=100, value=st.session_state.current_unit_value)

            st.markdown("---")
            col_submit, col_reset = st.columns(2)
            with col_submit:
                submitted = st.form_submit_button("è©•ä¾¡å®Ÿè¡Œ", use_container_width=True)
            with col_reset:
                reset_button = st.form_submit_button("å…¥åŠ›ã‚¯ãƒªã‚¢", use_container_width=True)

            if reset_button:
                st.session_state.markdown_input_prev = ''
                st.session_state.rpt_number_prev = 1
                st.session_state.evaluated_data = pd.DataFrame()
                st.session_state.race_info = ""
                st.session_state.current_budget = 100000
                st.session_state.current_unit_value = 100
                st.rerun()

            if submitted:
                if not markdown_input.strip():
                    st.warning("å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                else:
                    try:
                        df_markdown, race_info = parse_markdown_race_table(markdown_input)
                        st.session_state.evaluated_data = evaluate_data(df_markdown, rpt_number)
                        st.session_state.race_info = race_info
                        st.session_state.markdown_input_prev = markdown_input
                        st.session_state.rpt_number_prev = rpt_number
                        st.success(f"âœ… è©•ä¾¡å®Œäº†ï½œ{race_info}")

                        investment_recs = generate_investment_recommendations(st.session_state.evaluated_data)
                        if not investment_recs.empty:
                            final_recs = investment_recs[investment_recs['è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™'] > 1.0].copy()
                            if not final_recs.empty:
                                st.success("æŠ•è³‡å¯¾è±¡ã®æ¨å¥¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ã€ğŸ“ˆ æŠ•è³‡ç«¶é¦¬ã€ã‚¿ãƒ–ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
                            else:
                                st.info("æŠ•è³‡æ¨å¥¨é¦¬ã¯ã„ã¾ã—ãŸãŒã€æœ€ä½ã‚ªãƒƒã‚ºæ¡ä»¶(1.0å€è¶…)ã‚’æº€ãŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
                        else:
                            st.info("ã“ã®ãƒ¬ãƒ¼ã‚¹ã«æŠ•è³‡æ¨å¥¨é¦¬åˆ¸ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    except Exception as e:
                        st.error(f"è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    with tab2:
        if not st.session_state.evaluated_data.empty:
            investment_recs_raw = generate_investment_recommendations(st.session_state.evaluated_data)
            final_investment_recs = pd.DataFrame()
            if not investment_recs_raw.empty:
                final_investment_recs = investment_recs_raw[investment_recs_raw['è¤‡å‹ã‚ªãƒƒã‚ºä¸‹é™'] > 1.0].copy()
            
            render_investment_ui(final_investment_recs, st.session_state.race_info)
        else:
            st.info("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‚¿ãƒ–ã§è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    with tab3:
        if not st.session_state.evaluated_data.empty:
            render_enjoyment_ui(st.session_state.evaluated_data, performance_db, st.session_state.race_info)
        else:
            st.info("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‚¿ãƒ–ã§è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if __name__ == '__main__':
    main()